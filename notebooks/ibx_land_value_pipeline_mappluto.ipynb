{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec038e3",
   "metadata": {},
   "source": [
    "# IBX Land Value Uplift and Value Capture Pipeline (MapPLUTO + DOF Market Land Values)\n",
    "\n",
    "This notebook implements a modular geospatial and fiscal analysis pipeline to estimate how the proposed **Interborough Express (IBX)** could increase **land values** and **property tax revenue** in New York City, using:\n",
    "\n",
    "- **Parcel geometries and assessed land values** from NYC Department of City Planning’s **MapPLUTO** feature layer.\n",
    "- **Current market land values** from NYC Department of Finance’s parcel-level **assessment CSV**.\n",
    "- **Proposed IBX station locations** from `data/stations_ibx.geojson`, which provides the coordinates of each proposed station along the alignment.\n",
    "\n",
    "The pipeline is loosely modeled on the value-capture framework used by Gupta, Van Nieuwerburgh, and Kontokosta in *“Take the Q Train: Value Capture of Public Infrastructure Projects”* (NBER Working Paper 26789), adapted to a simpler, transparent, parcel-based implementation.\n",
    "\n",
    "**Key data linkages and fields:**\n",
    "\n",
    "- **Geometry & parcel IDs:** MapPLUTO 25v3  \n",
    "  - CRS: `EPSG:2263` (NAD83 / New York Long Island, US feet).  \n",
    "  - IDs: `BoroCode`, `Block`, `Lot`, `BBL`.  \n",
    "  - Assessed land: `AssessLand`.  \n",
    "  - Ownership & use: `OwnerType` (type of ownership) and `LandUse` (01–11 land-use categories).\n",
    "\n",
    "- **Valuations:** DOF assessment CSV  \n",
    "  - IDs: `BORO`, `BLOCK`, `LOT` → constructed **BBL**.  \n",
    "  - **Current market land value:** `CURMKTLAND`.  \n",
    "  - We **do not use** DOF assessed-land fields; instead we rely on MapPLUTO’s `AssessLand` (which itself is sourced from DOF but packaged in PLUTO).\n",
    "\n",
    "- **IBX alignment:**  \n",
    "  - Station locations and order come from `data/stations_ibx.geojson`.  \n",
    "  - The notebook builds a LineString alignment by connecting stations in order of a `sequence` column in that file.\n",
    "\n",
    "**High-level methodology:**\n",
    "\n",
    "1. **Represent the IBX alignment**\n",
    "   - Load IBX station locations from `data/stations_ibx.geojson`.\n",
    "   - Build an ordered **LineString** alignment joining the stations.\n",
    "   - Keep the code modular so alternate station sets/alignments can be swapped in.\n",
    "\n",
    "2. **Construct a 0.5-mile corridor (walkshed proxy)**\n",
    "   - Project IBX alignment and stations into **EPSG:2263** (feet).\n",
    "   - Buffer the IBX alignment by **0.5 miles (2,640 feet)** on both sides to approximate a half-mile corridor band.\n",
    "   - Keep the buffer in EPSG:2263 for clean intersection with MapPLUTO, with an option to export to WGS84 for mapping.\n",
    "\n",
    "3. **Load parcels (MapPLUTO) and link market valuations (DOF CSV)**\n",
    "   - Load **MapPLUTO** parcel geometries from the FileGDB at `data/nyc_mappluto_25v3_fgdb` (layer `MAPPLUTO`).  \n",
    "   - Load the **DOF assessment CSV** `data/DoF Valuation Data.csv`.\n",
    "   - Harmonize parcel identifiers (BORO/BLOCK/LOT → BBL) and merge **`CURMKTLAND`** onto MapPLUTO parcels.\n",
    "   - Use MapPLUTO’s **`AssessLand`** as the baseline **assessed land value**.\n",
    "\n",
    "4. **Select eligible parcels within the 0.5-mile IBX corridor**\n",
    "   - Spatially intersect parcels with the buffered alignment to define the **IBX corridor**.\n",
    "   - Exclude parcels **not eligible** for value capture (city/state/federal/public authority; parks/open space; clearly non-tax parcels) using MapPLUTO’s `OwnerType` and `LandUse`.  \n",
    "   - For each eligible parcel, retain:\n",
    "     - **Current market land value**: `CURMKTLAND` (DOF CSV).\n",
    "     - **Assessed land value**: `AssessLand` (MapPLUTO).\n",
    "\n",
    "5. **Compute baseline totals and uplift scenarios**\n",
    "   - Sum baseline **market land value** (`CURMKTLAND`) and **assessed land value** (`AssessLand`) in the IBX corridor.\n",
    "   - Compute scenario land values under **4%, 6%, 8%, and 10%** uplift assumptions.\n",
    "   - Visualize:\n",
    "     - Parcels in/out of the corridor.\n",
    "     - Corridor band + IBX line + stations.\n",
    "     - Eligible vs ineligible parcels within the band.\n",
    "\n",
    "6. **Gupta-style value capture estimation**\n",
    "   - Assume that only a **fraction of the value uplift** is captured automatically via existing NYC property taxes (e.g., **30.6%** passive capture share, following Gupta et al.).\n",
    "   - For each uplift scenario:\n",
    "     - Compute the **incremental private land value** created in the IBX corridor.\n",
    "     - Compute the **automatic property-tax capture** (baseline system) as that share of the uplift.\n",
    "     - Given an assumed **IBX capital cost** and a **time horizon / discount rate**, solve for the **additional constant annual surcharge rate** on uplifted land value needed so that the present value of that surcharge equals the remaining unfunded cost.\n",
    "\n",
    "7. **Final summary**\n",
    "   - Print a compact summary including:\n",
    "     - Baseline summed land market value (eligible parcels within IBX corridor).\n",
    "     - Scenario uplifts (4/6/8/10%) and incremental value.\n",
    "     - Assumed IBX capital cost, discount rate, horizon, and passive capture share.\n",
    "     - Implied **annual surcharge rates** needed to close the funding gap under each scenario.\n",
    "\n",
    "8. **Notebook export**\n",
    "   - Provide a final cell that **exports this notebook** using `jupyter nbconvert` (e.g. to HTML) so it can be downloaded from a Jupyter environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2397267a",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Import libraries and define file paths, CRS, and key assumptions used throughout the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d98e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports core libraries and sets global configuration for the analysis.\n",
    "# Update paths and assumptions here if your environment differs.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# File paths (relative to project root)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "\n",
    "\n",
    "# IBX station locations (authoritative station geometry)\n",
    "STATIONS_PATH = DATA_DIR / \"stations_ibx.geojson\"\n",
    "\n",
    "# MapPLUTO: FileGDB folder and layer name\n",
    "PLUTO_FGDB_PATH = DATA_DIR / \"nyc_mappluto_25v3_fgdb/MapPLUTO25v3.gdb\"\n",
    "PLUTO_LAYER_NAME = (\n",
    "    \"MapPLUTO_25v3_clipped\"  # adjust if the layer name differs in your FGDB\n",
    ")\n",
    "\n",
    "# DOF assessment CSV (valuation data, including CURMKTLAND)\n",
    "VALUATION_CSV_PATH = DATA_DIR / \"DoF Valuation Data.csv\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# CRS definitions\n",
    "# ------------------------------------------------------------------\n",
    "CRS_WGS84 = \"EPSG:4326\"  # geographic (lat/lon) for stations / maps\n",
    "CRS_NY_FT = \"EPSG:2263\"  # NAD83 / New York Long Island (US feet); MapPLUTO native\n",
    "\n",
    "# Half-mile buffer in feet\n",
    "HALF_MILE_FEET = 0.5 * 5280  # 2,640 ft\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# IBX alignment construction config\n",
    "# ------------------------------------------------------------------\n",
    "# Column used to sort stations along the IBX alignment. Must exist in stations_ibx.geojson.\n",
    "STATION_SORT_COLUMN = \"order\"  # e.g., 'sequence', 'order', etc.\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Parcel / valuation schema configuration\n",
    "# ------------------------------------------------------------------\n",
    "# MapPLUTO parcel ID fields\n",
    "PARCEL_ID_COLS = {\n",
    "    \"boro\": \"BoroCode\",  # integer 1-5\n",
    "    \"block\": \"Block\",  # integer\n",
    "    \"lot\": \"Lot\",  # integer\n",
    "    \"bbl\": \"BBL\",  # numeric BBL; we'll normalize to string\n",
    "}\n",
    "\n",
    "# DOF valuation CSV ID fields\n",
    "VALUATION_ID_COLS = {\n",
    "    \"boro\": \"BORO\",  # borough code\n",
    "    \"block\": \"BLOCK\",  # block\n",
    "    \"lot\": \"LOT\",  # lot\n",
    "    \"bbl\": None,  # build a BBL string from BORO/BLOCK/LOT\n",
    "}\n",
    "\n",
    "# Land value fields\n",
    "# - Market land value from DOF CSV.\n",
    "# - Assessed land value from MapPLUTO (AssessLand), *not* from DOF, to avoid redundancy.\n",
    "VALUATION_VALUE_FIELDS = {\n",
    "    \"land_market_value\": \"CURMKTLAND\",  # Current Market Assessed Land Value (DOF CSV)\n",
    "}\n",
    "PLUTO_ASSESSED_LAND_COL = \"AssessLand\"  # MapPLUTO assessed land value\n",
    "\n",
    "# MapPLUTO ownership / land-use fields\n",
    "PLUTO_OWNER_COL = \"OwnerType\"\n",
    "PLUTO_LANDUSE_COL = \"LandUse\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Gupta-style value capture assumptions\n",
    "# ------------------------------------------------------------------\n",
    "# Fraction of incremental market value captured (present value) by existing NYC tax system.\n",
    "PASSIVE_CAPTURE_SHARE = 0.306\n",
    "\n",
    "# IBX capital cost assumption (USD)\n",
    "IBX_CAPITAL_COST = 5_500_000_000  # $5.5B in 2027 dollars\n",
    "\n",
    "# Discount rate and horizon (for surcharge PV computation)\n",
    "DISCOUNT_RATE = 0.03  # 3% real discount rate\n",
    "HORIZON_YEARS = 30  # years\n",
    "\n",
    "# Uplift rates to analyze\n",
    "UPLIFT_RATES = [0.04, 0.06, 0.08, 0.10]\n",
    "\n",
    "print(\"Configuration loaded. Make sure paths and column names match your local data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f2e13",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Utility helpers for BBL construction, CRS handling, and basic plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines helper functions used across the pipeline.\n",
    "\n",
    "\n",
    "def construct_bbl_from_parts(boro, block, lot) -> str:\n",
    "    \"\"\"Build BBL string from boro/block/lot.\"\"\"\n",
    "\n",
    "    def clean(val):\n",
    "        s = str(val)\n",
    "        s = s.replace(\",\", \"\")\n",
    "        s = \"\".join(ch for ch in s if ch.isdigit())\n",
    "        return int(s)\n",
    "\n",
    "    b, blk, lt = (clean(x) for x in (boro, block, lot))\n",
    "    return f\"{b:1d}{blk:05d}{lt:04d}\"\n",
    "\n",
    "\n",
    "def add_bbl_column(\n",
    "    df: pd.DataFrame, id_cols: Dict[str, str], bbl_col_name: str = \"BBL\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Ensure a BBL column exists, either by using an existing column or constructing from BORO/BLOCK/LOT.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Input dataframe with parcel ID columns.\n",
    "    id_cols : dict\n",
    "        Mapping with keys 'boro', 'block', 'lot', 'bbl' giving column names in df.\n",
    "    bbl_col_name : str\n",
    "        Output column name for BBL.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    bbl_existing = id_cols.get(\"bbl\")\n",
    "    if bbl_existing and bbl_existing in df.columns:\n",
    "        # Normalize numeric BBL types to zero-padded strings\n",
    "        def _norm(v):\n",
    "            if pd.isna(v):\n",
    "                return np.nan\n",
    "            s = str(int(v))\n",
    "            return s.zfill(10)\n",
    "\n",
    "        df[bbl_col_name] = df[bbl_existing].apply(_norm)\n",
    "    else:\n",
    "        missing = [\n",
    "            k for k in (\"boro\", \"block\", \"lot\") if id_cols.get(k) not in df.columns\n",
    "        ]\n",
    "        if missing:\n",
    "            raise KeyError(f\"Cannot construct BBL; missing columns: {missing}\")\n",
    "        df[bbl_col_name] = [\n",
    "            construct_bbl_from_parts(b, blk, lt)\n",
    "            for b, blk, lt in zip(\n",
    "                df[id_cols[\"boro\"]], df[id_cols[\"block\"]], df[id_cols[\"lot\"]]\n",
    "            )\n",
    "        ]\n",
    "    return df\n",
    "\n",
    "\n",
    "def project_gdf(gdf: gpd.GeoDataFrame, to_crs: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Reproject a GeoDataFrame to the given CRS if needed.\"\"\"\n",
    "    if gdf.crs is None:\n",
    "        gdf = gdf.set_crs(to_crs)\n",
    "    if gdf.crs.to_string() != to_crs:\n",
    "        return gdf.to_crs(to_crs)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def quick_plot_base(parcels: gpd.GeoDataFrame, title: str = \"\", figsize=(8, 8)):\n",
    "    \"\"\"Quick base map of parcels for visual sanity checks.\"\"\"\n",
    "    ax = parcels.plot(edgecolor=\"none\", alpha=0.3, figsize=figsize)\n",
    "    ax.set_title(title)\n",
    "    plt.axis(\"equal\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17ef40",
   "metadata": {},
   "source": [
    "## 1. Draw IBX Alignment as Interpretable Geometry\n",
    "\n",
    "This step:\n",
    "\n",
    "1. Loads IBX station locations from `data/stations_ibx.geojson`.\n",
    "2. Sorts stations along the corridor using `STATION_SORT_COLUMN`.\n",
    "3. Builds a **LineString** representing the IBX alignment.\n",
    "4. Keeps everything modular so alternate station sets/alignments can be swapped in later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines functions to load station points and construct the IBX alignment line.\n",
    "\n",
    "\n",
    "def load_stations(\n",
    "    stations_path: Path, sort_col: str = STATION_SORT_COLUMN\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Load IBX station points from stations_ibx.geojson and sort them along the corridor.\n",
    "\n",
    "    The GeoJSON is assumed to contain:\n",
    "      - Point geometries for each proposed IBX station.\n",
    "      - A column (default: 'sequence') that orders stations along the line.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(stations_path)\n",
    "    if sort_col not in gdf.columns:\n",
    "        raise KeyError(\n",
    "            f\"Station sort column '{sort_col}' not found in {stations_path}. Columns: {list(gdf.columns)}\"\n",
    "        )\n",
    "    gdf = gdf.sort_values(sort_col).reset_index(drop=True)\n",
    "    if gdf.crs is None:\n",
    "        gdf = gdf.set_crs(CRS_WGS84)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def build_alignment_line(stations_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Construct a LineString alignment from ordered station points.\"\"\"\n",
    "    line = LineString(list(stations_gdf.geometry))\n",
    "    alignment = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"segment_id\": [\"IBX_main\"]}),\n",
    "        geometry=[line],\n",
    "        crs=stations_gdf.crs,\n",
    "    )\n",
    "    return alignment\n",
    "\n",
    "\n",
    "# Execute step 1\n",
    "stations_gdf = load_stations(STATIONS_PATH, sort_col=STATION_SORT_COLUMN)\n",
    "alignment_gdf = build_alignment_line(stations_gdf)\n",
    "\n",
    "print(\n",
    "    f\"Loaded {len(stations_gdf)} stations from {STATIONS_PATH} and built IBX alignment line.\"\n",
    ")\n",
    "alignment_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf4e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual sanity check: plot stations and IBX alignment over a simple base map.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "alignment_gdf.plot(ax=ax, color=\"black\", linewidth=2, label=\"IBX Alignment\")\n",
    "stations_gdf.plot(ax=ax, color=\"red\", markersize=30, label=\"Stations\")\n",
    "ax.set_title(\"IBX Stations and Alignment (from stations_ibx.geojson)\")\n",
    "ax.legend()\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce58b8e",
   "metadata": {},
   "source": [
    "## 2. Construct 0.5-Mile IBX Corridor Buffer\n",
    "\n",
    "Here we:\n",
    "\n",
    "1. Project the IBX alignment from WGS84 into **EPSG:2263** (feet), matching MapPLUTO.\n",
    "2. Buffer the alignment by **0.5 miles / 2,640 feet**.\n",
    "3. Keep the buffer in EPSG:2263 for clean intersection with parcels, with an optional WGS84 export for mapping.\n",
    "\n",
    "This yields a **corridor band** approximating a half-mile walkshed around the IBX right-of-way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2acc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell buffers the IBX alignment by 0.5 miles in EPSG:2263.\n",
    "\n",
    "\n",
    "def build_ibx_buffer(\n",
    "    alignment_gdf: gpd.GeoDataFrame,\n",
    "    buffer_distance_ft: float = HALF_MILE_FEET,\n",
    "    to_crs: str = CRS_NY_FT,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Buffer the IBX alignment by a given distance (in feet) and return a polygon GeoDataFrame in EPSG:2263.\"\"\"\n",
    "    aln_proj = alignment_gdf.to_crs(to_crs)\n",
    "    buffered_geom = aln_proj.buffer(buffer_distance_ft)\n",
    "    buffer_gdf = gpd.GeoDataFrame(\n",
    "        aln_proj.drop(columns=\"geometry\"), geometry=buffered_geom, crs=to_crs\n",
    "    )\n",
    "    buffer_gdf[\"buffer_ft\"] = buffer_distance_ft\n",
    "    return buffer_gdf\n",
    "\n",
    "\n",
    "ibx_buffer_gdf = build_ibx_buffer(alignment_gdf, buffer_distance_ft=HALF_MILE_FEET)\n",
    "\n",
    "print(\"IBX buffer geometry (EPSG:2263):\")\n",
    "ibx_buffer_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe48454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual sanity check: IBX buffer plus alignment (plotted in projected coordinates).\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ibx_buffer_gdf.plot(\n",
    "    ax=ax, color=\"lightblue\", alpha=0.3, edgecolor=\"blue\", label=\"0.5 mile buffer\"\n",
    ")\n",
    "alignment_gdf.to_crs(CRS_NY_FT).plot(\n",
    "    ax=ax, color=\"black\", linewidth=2, label=\"IBX alignment\"\n",
    ")\n",
    "ax.set_title(\"IBX 0.5-Mile Corridor Buffer (EPSG:2263)\")\n",
    "ax.legend()\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b6f14",
   "metadata": {},
   "source": [
    "## 3. Load Parcel Geometries (MapPLUTO) and Link DOF Market Land Values\n",
    "\n",
    "This step:\n",
    "\n",
    "1. Loads **MapPLUTO** parcel geometries from the file geodatabase at `data/nyc_mappluto_25v3_fgdb` (layer `MapPLUTO_25v3_clipped`), in **EPSG:2263**.  \n",
    "2. Loads the **DOF assessment CSV** containing `CURMKTLAND` and other fields.\n",
    "3. Ensures both datasets share a common **BBL identifier** (constructed from BORO/BLOCK/LOT where needed).  \n",
    "4. Merges **current market land value** (`CURMKTLAND`) onto MapPLUTO parcels.\n",
    "5. Uses MapPLUTO’s **`AssessLand`** as the parcel-level **assessed land value**, avoiding redundant DOF assessed fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines functions to load MapPLUTO and DOF CSV, harmonize IDs, and merge valuations.\n",
    "\n",
    "\n",
    "def load_parcels_from_fgdb(\n",
    "    fgdb_path: Path,\n",
    "    layer_name: str = PLUTO_LAYER_NAME,\n",
    "    parcel_id_cols: Dict[str, str] = PARCEL_ID_COLS,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Load MapPLUTO parcels from a FileGDB and ensure a BBL column exists (string).\"\"\"\n",
    "    gdf = gpd.read_file(fgdb_path, layer=layer_name)\n",
    "    gdf = project_gdf(gdf, to_crs=CRS_NY_FT)\n",
    "    gdf = add_bbl_column(gdf, parcel_id_cols, bbl_col_name=\"BBL\")\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def _clean_numeric(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Strip non-digits (e.g., commas) and return as string.\"\"\"\n",
    "    return series.astype(str).str.replace(r\"\\D\", \"\", regex=True)\n",
    "\n",
    "\n",
    "def load_valuation_csv(\n",
    "    csv_path: Path,\n",
    "    id_cols: Dict[str, str] = VALUATION_ID_COLS,\n",
    "    value_fields: Dict[str, str] = VALUATION_VALUE_FIELDS,\n",
    ") -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, dtype=str, low_memory=False)\n",
    "\n",
    "    # Clean IDs and build BBL\n",
    "    for col in (id_cols[\"boro\"], id_cols[\"block\"], id_cols[\"lot\"]):\n",
    "        df[col] = df[col].astype(str).str.replace(r\"\\D\", \"\", regex=True)\n",
    "    df = add_bbl_column(df, id_cols, bbl_col_name=\"BBL\")\n",
    "\n",
    "    missing = [v for v in value_fields.values() if v not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing value columns: {missing}\")\n",
    "\n",
    "    # Clean and numeric value columns, then collapse duplicate BBLs\n",
    "    for col in value_fields.values():\n",
    "        df[col] = (\n",
    "            df[col]\n",
    "            .astype(str)\n",
    "            .str.replace(r\"[^0-9.\\-]\", \"\", regex=True)\n",
    "            .replace(\"\", pd.NA)\n",
    "            .astype(float)\n",
    "        )\n",
    "    agg_spec = {col: \"sum\" for col in value_fields.values()}\n",
    "    df = df.groupby(\"BBL\", as_index=False).agg(agg_spec)\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_parcels_and_values(\n",
    "    parcels_gdf: gpd.GeoDataFrame,\n",
    "    values_df: pd.DataFrame,\n",
    "    value_fields: Dict[str, str] = VALUATION_VALUE_FIELDS,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Merge valuation data onto parcels via BBL and ensure numeric land value fields.\"\"\"\n",
    "    merged = parcels_gdf.merge(\n",
    "        values_df[[\"BBL\"] + list(value_fields.values())],\n",
    "        on=\"BBL\",\n",
    "        how=\"left\",\n",
    "        validate=\"1:1\",\n",
    "    )\n",
    "    for label, col in value_fields.items():\n",
    "        merged[col] = pd.to_numeric(merged[col], errors=\"coerce\")\n",
    "    if PLUTO_ASSESSED_LAND_COL in merged.columns:\n",
    "        merged[PLUTO_ASSESSED_LAND_COL] = pd.to_numeric(\n",
    "            merged[PLUTO_ASSESSED_LAND_COL], errors=\"coerce\"\n",
    "        )\n",
    "    else:\n",
    "        raise KeyError(\n",
    "            f\"Expected MapPLUTO assessed land column '{PLUTO_ASSESSED_LAND_COL}' not found.\"\n",
    "        )\n",
    "    return merged\n",
    "\n",
    "\n",
    "# Execute data loading\n",
    "parcels_gdf = load_parcels_from_fgdb(PLUTO_FGDB_PATH, layer_name=PLUTO_LAYER_NAME)\n",
    "print(f\"Loaded {len(parcels_gdf):,} parcels from MapPLUTO. CRS: {parcels_gdf.crs}\")\n",
    "\n",
    "valuation_df = load_valuation_csv(VALUATION_CSV_PATH)\n",
    "print(f\"Loaded {len(valuation_df):,} valuation rows from DOF CSV (deduped by BBL).\")\n",
    "\n",
    "parcels_with_values_gdf = merge_parcels_and_values(parcels_gdf, valuation_df)\n",
    "print(f\"Merged parcels and valuation data. Rows: {len(parcels_with_values_gdf):,}\")\n",
    "\n",
    "parcels_with_values_gdf[\n",
    "    [\"BBL\", \"AssessLand\", VALUATION_VALUE_FIELDS[\"land_market_value\"]]\n",
    "].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc4182",
   "metadata": {},
   "source": [
    "## 4. Select IBX-Proximate, Value-Capture-Eligible Parcels\n",
    "\n",
    "We now:\n",
    "\n",
    "1. Select MapPLUTO parcels whose geometry intersects the **0.5-mile IBX buffer** (all work in EPSG:2263).\n",
    "2. Apply **eligibility filters** to remove parcels that are not plausible value-capture targets, using:\n",
    "   - `OwnerType`: owner categories (e.g., private vs public).\n",
    "   - `LandUse`: 11 land-use categories derived from DOF building classes.\n",
    "\n",
    "Illustrative heuristic (tunable):\n",
    "\n",
    "- **Eligible OwnerType**: P (private) and blank (unknown, usually private).  \n",
    "- **Ineligible LandUse**: 07 (Transportation & Utility), 08 (Public Facilities & Institutions), 09 (Open Space & Outdoor Recreation), 10 (Parking Facilities), 11 (Vacant Land).  \n",
    "\n",
    "The exact codes will depend on the legal definition of the value-capture base; this code keeps the filters centralized and easily editable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines functions to perform the buffer intersection and eligibility filtering.\n",
    "\n",
    "### REMEMBER TO EXCLUDE ALL INELIGIBLE PARCELS IN FINAL ANALYSIS ###\n",
    "\n",
    "from shapely import union_all  # shapely>=2\n",
    "\n",
    "\n",
    "def select_parcels_in_buffer(\n",
    "    parcels_gdf: gpd.GeoDataFrame, buffer_gdf: gpd.GeoDataFrame\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Return parcels whose geometry intersects the IBX buffer polygon (all in EPSG:2263).\"\"\"\n",
    "    parcels_proj = project_gdf(parcels_gdf, to_crs=CRS_NY_FT)\n",
    "    buffer_proj = project_gdf(buffer_gdf, to_crs=CRS_NY_FT)\n",
    "    buffer_union = union_all(buffer_proj.geometry)\n",
    "    mask = parcels_proj.intersects(buffer_union)\n",
    "    return parcels_proj.loc[mask].copy()\n",
    "\n",
    "\n",
    "def filter_eligible_parcels(\n",
    "    parcels_gdf: gpd.GeoDataFrame,\n",
    "    owner_col: str = PLUTO_OWNER_COL,\n",
    "    landuse_col: str = PLUTO_LANDUSE_COL,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Keep parcels that are likely taxable; drop public owners and public/park land uses.\"\"\"\n",
    "    gdf = parcels_gdf.copy()\n",
    "\n",
    "    # Drop obviously public owners; keep everything else (including unknowns)\n",
    "    if owner_col in gdf.columns:\n",
    "        owner_series = gdf[owner_col].astype(str).str.upper().fillna(\"\")\n",
    "        public_owner_types = {\n",
    "            \"C\",\n",
    "            \"S\",\n",
    "            \"F\",\n",
    "            \"A\",\n",
    "            \"M\",\n",
    "        }  # City/State/Federal/Authority/Muni\n",
    "        mask_owner = ~owner_series.isin(public_owner_types)\n",
    "    else:\n",
    "        mask_owner = np.ones(len(gdf), dtype=bool)\n",
    "\n",
    "    # Drop public facilities and open space/parks; keep other uses\n",
    "    if landuse_col in gdf.columns:\n",
    "        landuse_series = gdf[landuse_col].astype(str).str.zfill(2)\n",
    "        ineligible_landuse = {\"07\", \"08\"}  # 07 public facilities, 08 open space/parks\n",
    "        mask_land = ~landuse_series.isin(ineligible_landuse)\n",
    "    else:\n",
    "        mask_land = np.ones(len(gdf), dtype=bool)\n",
    "\n",
    "    return gdf.loc[mask_owner & mask_land].copy()\n",
    "\n",
    "\n",
    "# Execute selection and filtering\n",
    "parcels_ibx_corridor_gdf = select_parcels_in_buffer(\n",
    "    parcels_with_values_gdf, ibx_buffer_gdf\n",
    ")\n",
    "print(f\"Parcels intersecting IBX 0.5-mile corridor: {len(parcels_ibx_corridor_gdf):,}\")\n",
    "\n",
    "eligible_ibx_parcels_gdf = filter_eligible_parcels(parcels_ibx_corridor_gdf)\n",
    "print(f\"Eligible parcels within IBX corridor: {len(eligible_ibx_parcels_gdf):,}\")\n",
    "\n",
    "eligible_ibx_parcels_gdf[\n",
    "    [\"BBL\", \"AssessLand\", VALUATION_VALUE_FIELDS[\"land_market_value\"]]\n",
    "].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual inspection: parcels within IBX corridor, highlighting eligible vs ineligible (projected CRS).\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "parcels_ibx_corridor_gdf.plot(\n",
    "    ax=ax, color=\"lightgrey\", linewidth=0, alpha=0.4, label=\"In-corridor parcels\"\n",
    ")\n",
    "eligible_ibx_parcels_gdf.plot(\n",
    "    ax=ax, color=\"orange\", linewidth=0, alpha=0.7, label=\"Eligible parcels\"\n",
    ")\n",
    "\n",
    "ibx_buffer_gdf.boundary.plot(\n",
    "    ax=ax, color=\"blue\", linewidth=1, label=\"0.5 mile buffer boundary\"\n",
    ")\n",
    "alignment_gdf.to_crs(CRS_NY_FT).plot(\n",
    "    ax=ax, color=\"black\", linewidth=2, label=\"IBX alignment\"\n",
    ")\n",
    "stations_gdf.to_crs(CRS_NY_FT).plot(ax=ax, color=\"red\", markersize=15, label=\"Stations\")\n",
    "\n",
    "ax.set_title(\"Parcels within IBX 0.5-Mile Corridor (eligible vs ineligible)\")\n",
    "ax.legend()\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af8717",
   "metadata": {},
   "source": [
    "## 5. Baseline Land Value and Uplift Scenarios\n",
    "\n",
    "For parcels that are both:\n",
    "\n",
    "- within the **0.5-mile IBX corridor**, and\n",
    "- **eligible** for value capture,\n",
    "\n",
    "we:\n",
    "\n",
    "1. Sum baseline **market land value** (`CURMKTLAND`) and **assessed land value** (`AssessLand`).\n",
    "2. Compute scenario land values under **4%, 6%, 8%, and 10%** uplift assumptions.\n",
    "3. Store the results in a tidy DataFrame for later use in the value-capture calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca52602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell computes baseline land values and simple uplift scenarios.\n",
    "\n",
    "land_mv_col = VALUATION_VALUE_FIELDS[\"land_market_value\"]\n",
    "land_av_col = PLUTO_ASSESSED_LAND_COL\n",
    "\n",
    "\n",
    "def compute_baseline_and_uplifts(\n",
    "    parcels_gdf: gpd.GeoDataFrame,\n",
    "    uplift_rates: Iterable[float] = UPLIFT_RATES,\n",
    "    land_mv_col: str = land_mv_col,\n",
    "    land_av_col: str = land_av_col,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute baseline land value and uplift scenarios for eligible parcels.\"\"\"\n",
    "    baseline_land_mv = parcels_gdf[land_mv_col].sum(skipna=True)\n",
    "    baseline_land_av = parcels_gdf[land_av_col].sum(skipna=True)\n",
    "\n",
    "    records = []\n",
    "    for r in uplift_rates:\n",
    "        scenario_mv = baseline_land_mv * (1 + r)\n",
    "        incremental = scenario_mv - baseline_land_mv\n",
    "        records.append(\n",
    "            {\n",
    "                \"uplift_rate\": r,\n",
    "                \"baseline_land_market_value\": baseline_land_mv,\n",
    "                \"baseline_land_assessed_value\": baseline_land_av,\n",
    "                \"scenario_land_market_value\": scenario_mv,\n",
    "                \"incremental_land_value\": incremental,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "uplift_summary_df = compute_baseline_and_uplifts(eligible_ibx_parcels_gdf)\n",
    "uplift_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10391f",
   "metadata": {},
   "source": [
    "## 6. Gupta-Style Value Capture Tax-Rate Estimation\n",
    "\n",
    "We adopt a simplified version of the Gupta–Van Nieuwerburgh–Kontokosta framework:\n",
    "\n",
    "1. For each uplift scenario, let \\( \\Delta V \\) be the **incremental market land value** in the IBX corridor.\n",
    "2. Assume the existing tax system passively captures a fixed share \\( \\theta \\) of that uplift in present value (default \\( \\theta = 0.306 \\)).\n",
    "3. Remaining unfunded cost: \\( C_{gap} = \\max(C - \\theta \\Delta V, 0) \\), where \\( C \\) is IBX capital cost.\n",
    "4. Assume a constant **annual surcharge rate** \\( \\tau \\) on the uplifted land value (\\( \\Delta V \\)) over \\( T \\) years at discount rate \\( r \\):\n",
    "   - Annual surcharge revenue: \\( \\tau \\Delta V \\).\n",
    "   - Present value: \\( \\tau \\Delta V A(r, T) \\), where \\( A(r, T) = \\frac{1 - (1+r)^{-T}}{r} \\).\n",
    "   - Solve for \\( \\tau \\) such that \\( \\tau \\Delta V A(r,T) = C_{gap} \\):\n",
    "     \\[\n",
    "     \\tau = \\frac{C_{gap}}{\\Delta V A(r, T)}.\n",
    "     \\]\n",
    "\n",
    "We report \\( \\tau \\) as an **annual value-capture tax rate** on the incremental land value (e.g., 0.5% of uplift per year).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines value-capture functions using the simplified Gupta-style framework.\n",
    "\n",
    "\n",
    "def annuity_factor(r: float, T: int) -> float:\n",
    "    \"\"\"Present-value factor of a $1-per-year annuity over T years at rate r.\"\"\"\n",
    "    if r <= 0:\n",
    "        return float(T)\n",
    "    return (1 - (1 + r) ** (-T)) / r\n",
    "\n",
    "\n",
    "def compute_surcharge_rate_for_scenario(\n",
    "    incremental_value: float,\n",
    "    capital_cost: float = IBX_CAPITAL_COST,\n",
    "    passive_capture_share: float = PASSIVE_CAPTURE_SHARE,\n",
    "    discount_rate: float = DISCOUNT_RATE,\n",
    "    horizon_years: int = HORIZON_YEARS,\n",
    "):\n",
    "    \"\"\"Compute funding gap and implied annual surcharge rate on uplifted land value.\"\"\"\n",
    "    passive_capture_pv = passive_capture_share * incremental_value\n",
    "    funding_gap = max(capital_cost - passive_capture_pv, 0)\n",
    "    A = annuity_factor(discount_rate, horizon_years)\n",
    "\n",
    "    if incremental_value <= 0 or A <= 0 or funding_gap == 0:\n",
    "        surcharge_rate = 0.0\n",
    "    else:\n",
    "        surcharge_rate = funding_gap / (incremental_value * A)\n",
    "\n",
    "    return {\n",
    "        \"incremental_value\": incremental_value,\n",
    "        \"passive_capture_pv\": passive_capture_pv,\n",
    "        \"funding_gap\": funding_gap,\n",
    "        \"annuity_factor\": A,\n",
    "        \"surcharge_rate\": surcharge_rate,\n",
    "    }\n",
    "\n",
    "\n",
    "def attach_value_capture_results(\n",
    "    uplift_df: pd.DataFrame,\n",
    "    capital_cost: float = IBX_CAPITAL_COST,\n",
    "    passive_capture_share: float = PASSIVE_CAPTURE_SHARE,\n",
    "    discount_rate: float = DISCOUNT_RATE,\n",
    "    horizon_years: int = HORIZON_YEARS,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Augment the uplift summary with Gupta-style value capture metrics for each scenario.\"\"\"\n",
    "    records = []\n",
    "    for _, row in uplift_df.iterrows():\n",
    "        vc = compute_surcharge_rate_for_scenario(\n",
    "            incremental_value=row[\"incremental_land_value\"],\n",
    "            capital_cost=capital_cost,\n",
    "            passive_capture_share=passive_capture_share,\n",
    "            discount_rate=discount_rate,\n",
    "            horizon_years=horizon_years,\n",
    "        )\n",
    "        rec = row.to_dict()\n",
    "        rec.update(vc)\n",
    "        records.append(rec)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "value_capture_df = attach_value_capture_results(uplift_summary_df)\n",
    "value_capture_df[\n",
    "    [\n",
    "        \"uplift_rate\",\n",
    "        \"baseline_land_market_value\",\n",
    "        \"scenario_land_market_value\",\n",
    "        \"incremental_land_value\",\n",
    "        \"passive_capture_pv\",\n",
    "        \"funding_gap\",\n",
    "        \"surcharge_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present surcharge rates in a more interpretable way (% of incremental land value per year).\n",
    "\n",
    "summary_display = value_capture_df.copy()\n",
    "summary_display[\"surcharge_rate_pct_per_year\"] = 100 * summary_display[\"surcharge_rate\"]\n",
    "summary_display[\n",
    "    [\n",
    "        \"uplift_rate\",\n",
    "        \"incremental_land_value\",\n",
    "        \"passive_capture_pv\",\n",
    "        \"funding_gap\",\n",
    "        \"surcharge_rate_pct_per_year\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464a5dc",
   "metadata": {},
   "source": [
    "## 7. Final Summary\n",
    "\n",
    "This cell prints a concise summary of:\n",
    "\n",
    "- Baseline summed **market land value** (`CURMKTLAND`) and **assessed land value** (`AssessLand`) in the IBX corridor (eligible parcels only).\n",
    "- Scenario uplift values (4%, 6%, 8%, 10%).\n",
    "- IBX capital cost and Gupta-style assumptions.\n",
    "- Implied annual value-capture surcharge rates needed to close the funding gap under each scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b4df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell prints a human-readable summary of key results.\n",
    "\n",
    "baseline_land_mv = uplift_summary_df[\"baseline_land_market_value\"].iloc[0]\n",
    "baseline_land_av = uplift_summary_df[\"baseline_land_assessed_value\"].iloc[0]\n",
    "\n",
    "print(\"=== IBX Land Value and Value Capture Summary ===\\n\")\n",
    "print(f\"Eligible IBX-corridor parcels: {len(eligible_ibx_parcels_gdf):,}\")\n",
    "print(f\"Baseline summed land MARKET value (CURMKTLAND):  ${baseline_land_mv:,.0f}\")\n",
    "print(f\"Baseline summed land ASSESSED value (AssessLand): ${baseline_land_av:,.0f}\\n\")\n",
    "\n",
    "print(f\"IBX capital cost assumption:          ${IBX_CAPITAL_COST:,.0f}\")\n",
    "print(f\"Passive capture share (Gupta-style):  {PASSIVE_CAPTURE_SHARE:.3f}\")\n",
    "print(f\"Discount rate:                         {DISCOUNT_RATE:.3%}\")\n",
    "print(f\"Horizon (years):                       {HORIZON_YEARS}\\n\")\n",
    "\n",
    "for _, row in value_capture_df.iterrows():\n",
    "    rate_pct = 100 * row[\"surcharge_rate\"]\n",
    "    print(\n",
    "        f\"Uplift scenario: {row['uplift_rate'] * 100:.0f}% uplift in land market value\"\n",
    "    )\n",
    "    print(f\"  Incremental land value:     ${row['incremental_land_value']:,.0f}\")\n",
    "    print(f\"  Passive tax capture (PV):   ${row['passive_capture_pv']:,.0f}\")\n",
    "    print(f\"  Remaining funding gap:      ${row['funding_gap']:,.0f}\")\n",
    "    print(\n",
    "        f\"  Required surcharge rate:    {rate_pct:.3f}% of incremental land value per year\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
